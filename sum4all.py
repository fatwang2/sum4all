import requests
import json
import re
import plugins
from bridge.reply import Reply, ReplyType
from bridge.context import ContextType
from channel.chat_message import ChatMessage
from plugins import *
from common.log import logger
from common.expired_dict import ExpiredDict
import os
from docx import Document
import markdown
import tiktoken
import jieba
import fitz
from openpyxl import load_workbook
import csv
from bs4 import BeautifulSoup
from pptx import Presentation
import base64
from urllib.parse import urlparse
from wsgiref.handlers import format_date_time

import _thread as thread
import datetime
import hashlib
import hmac
from urllib.parse import urlparse
import ssl
from time import mktime
from urllib.parse import urlencode
from wsgiref.handlers import format_date_time
import websocket  # ä½¿ç”¨websocket_client

EXTENSION_TO_TYPE = {
    'pdf': 'pdf',
    'doc': 'docx', 'docx': 'docx',
    'md': 'md',
    'txt': 'txt',
    'xls': 'excel', 'xlsx': 'excel',
    'csv': 'csv',
    'html': 'html', 'htm': 'html',
    'ppt': 'ppt', 'pptx': 'ppt'
}
imageunderstanding_url = "wss://spark-api.cn-huabei-1.xf-yun.com/v2.1/image"#äº‘ç«¯ç¯å¢ƒçš„æœåŠ¡åœ°å€
text =[{"role": "user", "content": "", "content_type":"image"}]

@plugins.register(
    name="sum4all",
    desire_priority=2,
    desc="A plugin for summarizing all things",
    version="0.6.5",
    author="fatwang2",
)



class sum4all(Plugin):
    def __init__(self):
        super().__init__()
        try:
            curdir = os.path.dirname(__file__)
            config_path = os.path.join(curdir, "config.json")
            if os.path.exists(config_path):
                with open(config_path, "r", encoding="utf-8") as f:
                    self.config = json.load(f)
            else:
                # ä½¿ç”¨çˆ¶ç±»çš„æ–¹æ³•æ¥åŠ è½½é…ç½®
                self.config = super().load_config()

                if not self.config:
                    raise Exception("config.json not found")
            # è®¾ç½®äº‹ä»¶å¤„ç†å‡½æ•°
            self.handlers[Event.ON_HANDLE_CONTEXT] = self.on_handle_context
            self.params_cache = ExpiredDict(300)
            self.host = urlparse(imageunderstanding_url).netloc
            self.path = urlparse(imageunderstanding_url).path
            self.ImageUnderstanding_url = imageunderstanding_url
            self.ws_context = dict()
            self.ws_answer = ""
            
            # ä»é…ç½®ä¸­æå–æ‰€éœ€çš„è®¾ç½®
            self.keys = self.config.get("keys", {})
            self.url_sum = self.config.get("url_sum", {})
            self.search_sum = self.config.get("search_sum", {})
            self.file_sum = self.config.get("file_sum", {})
            self.image_sum = self.config.get("image_sum", {})


            self.sum4all_key = self.keys.get("sum4all_key", "")
            self.gemini_key = self.keys.get("gemini_key", "")
            self.bibigpt_key = self.keys.get("bibigpt_key", "")
            self.outputLanguage = self.keys.get("outputLanguage", "zh-CN")
            self.opensum_key = self.keys.get("opensum_key", "")
            self.open_ai_api_key = self.keys.get("open_ai_api_key", "")
            self.model = self.keys.get("model", "gpt-3.5-turbo")
            self.open_ai_api_base = self.keys.get("open_ai_api_base", "https://api.openai.com/v1")
            self.xunfei_app_id = self.keys.get("xunfei_app_id", "")
            self.xunfei_api_key = self.keys.get("xunfei_api_key", "")
            self.xunfei_api_secret = self.keys.get("xunfei_api_secret", "")
            self.perplexity_key = self.keys.get("perplexity_key", "")

            # æå–sumæœåŠ¡çš„é…ç½®
            self.url_sum_enabled = self.url_sum.get("enabled", False)
            self.url_sum_service = self.url_sum.get("service", "")
            self.url_sum_group = self.url_sum.get("group", True)
            self.url_sum_qa_prefix = self.url_sum.get("qa_prefix", "é—®")
            self.url_sum_prompt = self.url_sum.get("prompt", "")

            self.search_sum_enabled = self.search_sum.get("enabled", False)
            self.search_sum_service = self.search_sum.get("service", "")
            self.search_sum_group = self.search_sum.get("group", True)
            self.search_sum_search_prefix = self.search_sum.get("search_prefix", "æœ")
            self.search_sum_prompt = self.search_sum.get("prompt", "")

            self.file_sum_enabled = self.file_sum.get("enabled", False)
            self.file_sum_service = self.file_sum.get("service", "")
            self.file_sum_group = self.file_sum.get("group", True)
            self.file_sum_qa_prefix = self.file_sum.get("qa_prefix", "é—®")
            self.file_sum_prompt = self.file_sum.get("prompt", "")

            self.image_sum_enabled = self.image_sum.get("enabled", False)
            self.image_sum_service = self.image_sum.get("service", "")
            self.image_sum_group = self.image_sum.get("group", True)
            self.image_sum_qa_prefix = self.image_sum.get("qa_prefix", "é—®")
            self.image_sum_prompt = self.image_sum.get("prompt", "")

            # åˆå§‹åŒ–æˆåŠŸæ—¥å¿—
            logger.info("[sum4all] inited.")
        except Exception as e:
            # åˆå§‹åŒ–å¤±è´¥æ—¥å¿—
            logger.warn(f"sum4all init failed: {e}")
    def on_handle_context(self, e_context: EventContext):
        context = e_context["context"]
        if context.type not in [ContextType.TEXT, ContextType.SHARING,ContextType.FILE,ContextType.IMAGE]:
            return
        msg: ChatMessage = e_context["context"]["msg"]
        user_id = msg.from_user_id
        content = context.content
        isgroup = e_context["context"].get("isgroup", False)

        url_match = re.match('https?://(?:[-\w.]|(?:%[\da-fA-F]{2}))+', content)
        unsupported_urls = re.search(r'.*finder\.video\.qq\.com.*|.*support\.weixin\.qq\.com/update.*|.*support\.weixin\.qq\.com/security.*|.*mp\.weixin\.qq\.com/mp/waerrpage.*', content)

            # æ£€æŸ¥è¾“å…¥æ˜¯å¦ä»¥"æœç´¢å‰ç¼€è¯" å¼€å¤´
        if content.startswith(self.search_sum_search_prefix) and self.file_sum_enabled:
            # Call new function to handle search operation
            self.call_service(content, e_context, "search")
            return
        
        if user_id in self.params_cache and ('last_file_content' in self.params_cache[user_id] or 'last_image_base64' in self.params_cache[user_id] or 'last_url' in self.params_cache[user_id]):
            # å¦‚æœå­˜åœ¨æœ€è¿‘ä¸€æ¬¡å¤„ç†çš„æ–‡ä»¶è·¯å¾„ï¼Œè§¦å‘æ–‡ä»¶ç†è§£å‡½æ•°
            if 'last_file_content' in self.params_cache[user_id] and content.startswith(self.file_sum_qa_prefix):
                logger.info('Content starts with the file_sum_qa_prefix.')
                # å»é™¤å…³é”®è¯å’Œç´§éšå…¶åçš„ç©ºæ ¼
                new_content = content[len(self.file_sum_qa_prefix):]
                self.params_cache[user_id]['prompt'] = new_content
                logger.info('params_cache for user has been successfully updated.')            
                self.handle_file(self.params_cache[user_id]['last_file_content'], e_context)
            # å¦‚æœå­˜åœ¨æœ€è¿‘ä¸€æ¬¡å¤„ç†çš„å›¾ç‰‡è·¯å¾„ï¼Œè§¦å‘å›¾ç‰‡ç†è§£å‡½æ•°
            elif 'last_image_base64' in self.params_cache[user_id] and content.startswith(self.image_sum_qa_prefix):
                logger.info('Content starts with the image_sum_qa_prefix.')
                # å»é™¤å…³é”®è¯å’Œç´§éšå…¶åçš„ç©ºæ ¼
                new_content = content[len(self.image_sum_qa_prefix):]
                self.params_cache[user_id]['prompt'] = new_content
                logger.info('params_cache for user has been successfully updated.')            
                if self.image_sum_service == "xunfei":
                    self.handle_xunfei_image(self.params_cache[user_id]['last_image_base64'], e_context)
                elif self.image_sum_service == "openai":
                    self.handle_openai_image(self.params_cache[user_id]['last_image_base64'], e_context)
                elif self.image_sum_service == "gemini":
                    self.handle_gemini_image(self.params_cache[user_id]['last_image_base64'], e_context)
            # å¦‚æœå­˜åœ¨æœ€è¿‘ä¸€æ¬¡å¤„ç†çš„URLï¼Œè§¦å‘URLç†è§£å‡½æ•°
            elif 'last_url' in self.params_cache[user_id] and content.startswith(self.url_sum_qa_prefix):
                logger.info('Content starts with the url_sum_qa_prefix.')
                # å»é™¤å…³é”®è¯å’Œç´§éšå…¶åçš„ç©ºæ ¼
                new_content = content[len(self.url_sum_qa_prefix):]
                self.params_cache[user_id]['prompt'] = new_content
                logger.info('params_cache for user has been successfully updated.')            
                self.call_service(self.params_cache[user_id]['last_url'], e_context ,"sum")
        if context.type == ContextType.FILE:
            if isgroup and not self.file_sum_group:
                # ç¾¤èŠä¸­å¿½ç•¥å¤„ç†æ–‡ä»¶
                logger.info("ç¾¤èŠæ¶ˆæ¯ï¼Œæ–‡ä»¶å¤„ç†åŠŸèƒ½å·²ç¦ç”¨")
                return
            logger.info("on_handle_context: å¤„ç†ä¸Šä¸‹æ–‡å¼€å§‹")
            context.get("msg").prepare()
            file_path = context.content
            logger.info(f"on_handle_context: è·å–åˆ°æ–‡ä»¶è·¯å¾„ {file_path}")
            
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥è¿›è¡Œæ–‡ä»¶æ€»ç»“
            if self.file_sum_enabled:
                # æ›´æ–°params_cacheä¸­çš„last_file_content
                self.params_cache[user_id] = {}
                file_content = self.extract_content(file_path)
                self.params_cache[user_id]['last_file_content'] = file_content
                logger.info('Updated last_file_content in params_cache for user.')
                self.handle_file(file_content, e_context)
            else:
                logger.info("æ–‡ä»¶æ€»ç»“åŠŸèƒ½å·²ç¦ç”¨ï¼Œä¸å¯¹æ–‡ä»¶å†…å®¹è¿›è¡Œå¤„ç†")
            # åˆ é™¤æ–‡ä»¶
            os.remove(file_path)
            logger.info(f"æ–‡ä»¶ {file_path} å·²åˆ é™¤")
        elif context.type == ContextType.IMAGE:
            if isgroup and not self.image_sum_group:
                # ç¾¤èŠä¸­å¿½ç•¥å¤„ç†å›¾ç‰‡
                logger.info("ç¾¤èŠæ¶ˆæ¯ï¼Œå›¾ç‰‡å¤„ç†åŠŸèƒ½å·²ç¦ç”¨")
                return
            logger.info("on_handle_context: å¼€å§‹å¤„ç†å›¾ç‰‡")
            context.get("msg").prepare()
            image_path = context.content
            logger.info(f"on_handle_context: è·å–åˆ°å›¾ç‰‡è·¯å¾„ {image_path}")
            
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥è¿›è¡Œå›¾ç‰‡æ€»ç»“
            if self.image_sum_enabled:
                # å°†å›¾ç‰‡è·¯å¾„è½¬æ¢ä¸ºBase64ç¼–ç çš„å­—ç¬¦ä¸²
                base64_image = self.encode_image_to_base64(image_path)
                # æ›´æ–°params_cacheä¸­çš„last_image_path
                self.params_cache[user_id] = {}
                self.params_cache[user_id]['last_image_base64'] = base64_image
                logger.info('Updated last_image_base64 in params_cache for user.')
                if self.image_sum_service == "xunfei":
                    self.handle_xunfei_image(base64_image, e_context)
                elif self.image_sum_service == "openai":
                    self.handle_openai_image(base64_image, e_context)
                elif self.image_sum_service == "gemini":
                    self.handle_gemini_image(base64_image, e_context)
            else:
                logger.info("å›¾ç‰‡æ€»ç»“åŠŸèƒ½å·²ç¦ç”¨ï¼Œä¸å¯¹å›¾ç‰‡å†…å®¹è¿›è¡Œå¤„ç†")
            # åˆ é™¤æ–‡ä»¶
            os.remove(image_path)
            logger.info(f"æ–‡ä»¶ {image_path} å·²åˆ é™¤")
        elif context.type == ContextType.SHARING:  #åŒ¹é…å¡ç‰‡åˆ†äº«
            if unsupported_urls:  #åŒ¹é…ä¸æ”¯æŒæ€»ç»“çš„å¡ç‰‡
                if isgroup:  ##ç¾¤èŠä¸­å¿½ç•¥
                    return
                else:  ##ç§èŠå›å¤ä¸æ”¯æŒ
                    logger.info("[sum4all] Unsupported URL : %s", content)
                    reply = Reply(type=ReplyType.TEXT, content="ä¸æ”¯æŒæ€»ç»“å°ç¨‹åºå’Œè§†é¢‘å·")
                    e_context["reply"] = reply
                    e_context.action = EventAction.BREAK_PASS
            else:  #åŒ¹é…æ”¯æŒæ€»ç»“çš„å¡ç‰‡
                if isgroup:  #å¤„ç†ç¾¤èŠæ€»ç»“
                    if self.url_sum_group:  #group_sharing = Trueè¿›è¡Œæ€»ç»“ï¼ŒFalseåˆ™å¿½ç•¥ã€‚
                        logger.info("[sum4all] Summary URL : %s", content)
                        # æ›´æ–°params_cacheä¸­çš„last_url
                        self.params_cache[user_id] = {}
                        self.params_cache[user_id]['last_url'] = content
                        logger.info('Updated last_url in params_cache for user.')
                        self.call_service(content, e_context, "sum")
                        return
                    else:
                        return
                else:  #å¤„ç†ç§èŠæ€»ç»“
                    logger.info("[sum4all] Summary URL : %s", content)
                    # æ›´æ–°params_cacheä¸­çš„last_url
                    self.params_cache[user_id] = {}
                    self.params_cache[user_id]['last_url'] = content
                    logger.info('Updated last_url in params_cache for user.')
                    self.call_service(content, e_context, "sum")
                    return
            
        elif url_match: #åŒ¹é…URLé“¾æ¥
            if unsupported_urls:  #åŒ¹é…ä¸æ”¯æŒæ€»ç»“çš„ç½‘å€
                logger.info("[sum4all] Unsupported URL : %s", content)
                reply = Reply(type=ReplyType.TEXT, content="ä¸æ”¯æŒæ€»ç»“å°ç¨‹åºå’Œè§†é¢‘å·")
                e_context["reply"] = reply
                e_context.action = EventAction.BREAK_PASS
            else:
                logger.info("[sum4all] Summary URL : %s", content)
                # æ›´æ–°params_cacheä¸­çš„last_url
                self.params_cache[user_id] = {}
                self.params_cache[user_id]['last_url'] = content
                logger.info('Updated last_url in params_cache for user.')
                self.call_service(content, e_context, "sum")
                return
    def call_service(self, content, e_context, service_type):
        if service_type == "search":
            if self.search_sum_service == "openai" or self.search_sum_service == "sum4all" or self.search_sum_service == "gemini":
                self.handle_search(content, e_context)
            elif self.search_sum_service == "perplexity":
                self.handle_perplexity(content, e_context)
        elif service_type == "sum":
            if self.url_sum_service == "bibigpt":
                self.handle_bibigpt(content, e_context)
            elif self.url_sum_service == "openai" or self.url_sum_service == "sum4all" or self.url_sum_service == "gemini":
                self.handle_url(content, e_context)
            elif self.url_sum_service == "opensum":
                self.handle_opensum(content, e_context)
 
        
    def short_url(self, long_url):
        url = "https://short.fatwang2.com"
        payload = {
            "url": long_url
        }        
        headers = {'Content-Type': "application/json"}
        response = requests.request("POST", url, json=payload, headers=headers)
        if response.status_code == 200:
            res_data = response.json()
            # ç›´æ¥ä»è¿”å›çš„ JSON ä¸­è·å–çŸ­é“¾æ¥
            short_url = res_data.get('shorturl', None)  
            
            if short_url:
                return short_url
        return None
    def handle_url(self, content, e_context):
        logger.info('Handling Sum4All request...')
        # æ ¹æ®sum_serviceçš„å€¼é€‰æ‹©APIå¯†é’¥å’ŒåŸºç¡€URL
        if self.url_sum_service == "openai":
            api_key = self.open_ai_api_key
            api_base = self.open_ai_api_base
            model = self.model
        elif self.url_sum_service == "sum4all":
            api_key = self.sum4all_key
            api_base = "https://pro.sum4all.site/v1"
            model = "sum4all"
        elif self.url_sum_service == "gemini":
            api_key = self.gemini_key
            model = "gemini"
            api_base = "https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key="
        else:
            logger.error(f"æœªçŸ¥çš„sum_serviceé…ç½®: {self.url_sum_service}")
            return
        
        msg: ChatMessage = e_context["context"]["msg"]
        user_id = msg.from_user_id
        user_params = self.params_cache.get(user_id, {})
        prompt = user_params.get('prompt', self.url_sum_prompt)
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {api_key}'
        }
        payload = json.dumps({
            "link": content,
            "prompt": prompt,
            "model": model,
            "base": api_base
        })
        additional_content = ""  # åœ¨ try å—ä¹‹å‰åˆå§‹åŒ– additional_content

        try:
            logger.info('Sending request to LLM...')
            api_url = "https://ai.sum4all.site"
            response = requests.post(api_url, headers=headers, data=payload)
            response.raise_for_status()
            logger.info('Received response from LLM.')
            response_data = response.json()  # è§£æå“åº”çš„ JSON æ•°æ®
            if response_data.get("success"):
                content = response_data["content"].replace("\\n", "\n")  # æ›¿æ¢ \\n ä¸º \n

                # æ–°å¢åŠ çš„éƒ¨åˆ†ï¼Œç”¨äºè§£æ meta æ•°æ®
                meta = response_data.get("meta", {})  # å¦‚æœæ²¡æœ‰ meta æ•°æ®ï¼Œåˆ™é»˜è®¤ä¸ºç©ºå­—å…¸
                title = meta.get("og:title", "")  # è·å– og:titleï¼Œå¦‚æœæ²¡æœ‰åˆ™é»˜è®¤ä¸ºç©ºå­—ç¬¦ä¸²
                # åªæœ‰å½“ title éç©ºæ—¶ï¼Œæ‰åŠ å…¥åˆ°å›å¤ä¸­
                if title:
                    additional_content += f"{title}\n\n"
                reply_content = additional_content + content  # å°†å†…å®¹åŠ å…¥å›å¤
                
            else:
                reply_content = "Content not found or error in response"

        except requests.exceptions.RequestException as e:
            # å¤„ç†å¯èƒ½å‡ºç°çš„é”™è¯¯
            logger.error(f"Error calling new combined api: {e}")
            reply_content = f"An error occurred: {e}"

        reply = Reply()
        reply.type = ReplyType.TEXT
        reply.content = f"{remove_markdown(reply_content)}\n\nğŸ’¬5minå†…è¾“å…¥{self.url_sum_qa_prefix}+é—®é¢˜ï¼Œå¯ç»§ç»­è¿½é—®"             
        e_context["reply"] = reply
        e_context.action = EventAction.BREAK_PASS
    def handle_bibigpt(self, content, e_context):    
        headers = {
            'Content-Type': 'application/json'
        }
        payload_params = {
            "url": content,
            "includeDetail": False,
            "promptConfig": {
                "outputLanguage": self.outputLanguage
            }
        }

        payload = json.dumps(payload_params)           
        try:
            api_url = f"https://bibigpt.co/api/open/{self.bibigpt_key}"
            response = requests.request("POST",api_url, headers=headers, data=payload)
            response.raise_for_status()
            data = json.loads(response.text)
            summary_original = data.get('summary', 'Summary not available')
            html_url = data.get('htmlUrl', 'HTML URL not available')
            # è·å–çŸ­é“¾æ¥
            short_url = self.short_url(html_url) 
            
            # å¦‚æœè·å–çŸ­é“¾æ¥å¤±è´¥ï¼Œä½¿ç”¨ html_url
            if short_url is None:
                short_url = html_url if html_url != 'HTML URL not available' else 'URL not available'
            
            # ç§»é™¤ "##æ‘˜è¦"ã€"## äº®ç‚¹" å’Œ "-"
            summary = summary_original.split("è¯¦ç»†ç‰ˆï¼ˆæ”¯æŒå¯¹è¯è¿½é—®ï¼‰")[0].replace("## æ‘˜è¦\n", "ğŸ“Œæ€»ç»“ï¼š").replace("## äº®ç‚¹\n", "").replace("- ", "")
        except requests.exceptions.RequestException as e:
            reply = f"An error occurred: {e}"

        reply = Reply()
        reply.type = ReplyType.TEXT
        reply.content = f"{summary}\n\nè¯¦ç»†é“¾æ¥ï¼š{short_url}"

        e_context["reply"] = reply
        e_context.action = EventAction.BREAK_PASS
    def handle_opensum(self, content, e_context):
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {self.opensum_key}'
        }
        payload = json.dumps({"link": content})
        try:
            api_url = "https://read.thinkwx.com/api/v1/article/summary"
            response = requests.request("POST",api_url, headers=headers, data=payload)
            response.raise_for_status()
            data = json.loads(response.text)
            summary_data = data.get('data', {})  # è·å–dataå­—æ®µ                
            summary_original = summary_data.get('summary', 'Summary not available')
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–URL
            url_pattern = r'https:\/\/[^\s]+'
            match = re.search(url_pattern, summary_original)
            html_url = match.group(0) if match else 'HTML URL not available'            
            # è·å–çŸ­é“¾æ¥
            short_url = self.short_url(html_url) if match else html_url
            # ç”¨äºç§»é™¤æ‘˜è¦ä¸­çš„URLåŠå…¶åçš„æ‰€æœ‰å†…å®¹
            url_pattern_remove = r'https:\/\/[^\s]+[\s\S]*'
            summary = re.sub(url_pattern_remove, '', summary_original).strip()        

        except requests.exceptions.RequestException as e:
            summary = f"An error occurred: {e}"
            short_url = 'URL not available'
        
        reply = Reply()
        reply.type = ReplyType.TEXT
        reply.content = f"{summary}\n\nè¯¦ç»†é“¾æ¥ï¼š{short_url}"

        e_context["reply"] = reply
        e_context.action = EventAction.BREAK_PASS    
    def handle_search(self, content, e_context):
        # æ ¹æ®sum_serviceçš„å€¼é€‰æ‹©APIå¯†é’¥å’ŒåŸºç¡€URL
        if self.search_sum_service == "openai":
            api_key = self.open_ai_api_key
            api_base = self.open_ai_api_base
            model = self.model
        elif self.search_sum_service == "sum4all":
            api_key = self.sum4all_key
            api_base = "https://pro.sum4all.site/v1"
            model = "sum4all"
        elif self.search_sum_service == "gemini":
            api_key = self.gemini_key
            model = "gemini"
            api_base = "https://generativelanguage.googleapis.com/v1beta/models"

        else:
            logger.error(f"æœªçŸ¥çš„search_serviceé…ç½®: {self.search_sum_service}")
            return
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {api_key}'
        }
        payload = json.dumps({
            "ur": content,
            "prompt": self.search_sum_prompt,
            "model": model,
            "base": api_base
        })
        try:
            api_url = "https://ai.sum4all.site"
            response = requests.post(api_url, headers=headers, data=payload)
            response.raise_for_status()
            response_data = response.json()  # è§£æå“åº”çš„ JSON æ•°æ®
            if response_data.get("success"):
                content = response_data["content"].replace("\\n", "\n")  # æ›¿æ¢ \\n ä¸º \n
                reply_content = content  # å°†å†…å®¹åŠ å…¥å›å¤

                # è§£æ meta æ•°æ®
                meta = response_data.get("meta", {})  # å¦‚æœæ²¡æœ‰ meta æ•°æ®ï¼Œåˆ™é»˜è®¤ä¸ºç©ºå­—å…¸
                title = meta.get("og:title", "")  # è·å– og:titleï¼Œå¦‚æœæ²¡æœ‰åˆ™é»˜è®¤ä¸ºç©ºå­—ç¬¦ä¸²
                og_url = meta.get("og:url", "")  # è·å– og:urlï¼Œå¦‚æœæ²¡æœ‰åˆ™é»˜è®¤ä¸ºç©ºå­—ç¬¦ä¸²
                # æ‰“å° title å’Œ og_url ä»¥è°ƒè¯•
                print("Title:", title)
                print("Original URL:", og_url)                
                # åªæœ‰å½“ title å’Œ url éç©ºæ—¶ï¼Œæ‰åŠ å…¥åˆ°å›å¤ä¸­
                if title:
                    reply_content += f"\n\nå‚è€ƒæ–‡ç« ï¼š{title}"
                if og_url:
                    short_url = self.short_url(og_url)  # è·å–çŸ­é“¾æ¥
                    reply_content += f"\n\nå‚è€ƒé“¾æ¥ï¼š{short_url}"                

            else:
                content = "Content not found or error in response"

        except requests.exceptions.RequestException as e:
            # å¤„ç†å¯èƒ½å‡ºç°çš„é”™è¯¯
            logger.error(f"Error calling new combined api: {e}")
            reply_content = f"An error occurred: {e}"

        reply = Reply()
        reply.type = ReplyType.TEXT
        reply.content = reply_content            
        e_context["reply"] = reply
        e_context.action = EventAction.BREAK_PASS
    def handle_perplexity(self, content, e_context):

        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {self.perplexity_key}'
        }
        data = {
            "model": "pplx-7b-online",
            "messages": [
                {"role": "system", "content": self.search_sum_prompt},
                {"role": "user", "content": content}
        ]
        }
        try:
            api_url = "https://api.perplexity.ai/chat/completions"
            response = requests.post(api_url, headers=headers, json=data)
            response.raise_for_status()
            # å¤„ç†å“åº”æ•°æ®
            response_data = response.json()
            # è¿™é‡Œå¯ä»¥æ ¹æ®ä½ çš„éœ€è¦å¤„ç†å“åº”æ•°æ®
            # è§£æ JSON å¹¶è·å– content
            if "choices" in response_data and len(response_data["choices"]) > 0:
                first_choice = response_data["choices"][0]
                if "message" in first_choice and "content" in first_choice["message"]:
                    content = first_choice["message"]["content"]
                else:
                    print("Content not found in the response")
            else:
                print("No choices available in the response")
        except requests.exceptions.RequestException as e:
            # å¤„ç†å¯èƒ½å‡ºç°çš„é”™è¯¯
            logger.error(f"Error calling perplexity: {e}")
        reply = Reply()
        reply.type = ReplyType.TEXT
        reply.content = f"{content}"
        e_context["reply"] = reply
        e_context.action = EventAction.BREAK_PASS
    def get_help_text(self, **kwargs):
        help_text = "ä¸ºä½ æ€»ç»“ä¸€åˆ‡ï¼Œå‘é€é“¾æ¥ã€å›¾ç‰‡ã€æ–‡ä»¶ï¼Œæˆ–ç›´æ¥æœç´¢ï¼Œä¸€åˆ‡éƒ½èƒ½ä¸ºä½ æ€»ç»“\n"
        return help_text
    def handle_file(self, content, e_context):
        logger.info("handle_file: å‘LLMå‘é€å†…å®¹æ€»ç»“è¯·æ±‚")
        # æ ¹æ®sum_serviceçš„å€¼é€‰æ‹©APIå¯†é’¥å’ŒåŸºç¡€URL
        if self.file_sum_service == "openai":
            api_key = self.open_ai_api_key
            api_base = self.open_ai_api_base
            model = self.model
        elif self.file_sum_service == "sum4all":
            api_key = self.sum4all_key
            api_base = "https://pro.sum4all.site/v1"
            model = "sum4all"
        elif self.file_sum_service == "gemini":
            api_key = self.gemini_key
            model = "gemini"
            api_base = "https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent"
        else:
            logger.error(f"æœªçŸ¥çš„sum_serviceé…ç½®: {self.file_sum_service}")
            return
        msg: ChatMessage = e_context["context"]["msg"]
        user_id = msg.from_user_id
        user_params = self.params_cache.get(user_id, {})
        prompt = user_params.get('prompt', self.file_sum_prompt)
        if model == "gemini":
            headers = {
                'Content-Type': 'application/json',
                'x-goog-api-key': {api_key}
            }
            data = {
            "contents": [
                {"role": "user", "parts": [{"text": prompt}]},
                {"role": "model", "parts": [{"text": ""}]},
                {"role": "user", "parts": [{"text": content}]}
            ],
            "generationConfig": {
                "maxOutputTokens": 800
            }
            }
            api_url = api_base
        else:
            headers = {
                'Content-Type': 'application/json',
                'Authorization': f'Bearer {api_key}'
            }
            data = {
                "model": model,
                "messages": [
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": content}
                ]
            }
            api_url = f"{api_base}/chat/completions"
        try:
            response = requests.post(api_url, headers=headers, data=json.dumps(data))
            response.raise_for_status()
            response_data = response.json()
            
            # è§£æ JSON å¹¶è·å– content
            if model == "gemini":
                if "candidates" in response_data and len(response_data["candidates"]) > 0:
                    first_candidate = response_data["candidates"][0]
                    if "content" in first_candidate:
                        if "parts" in first_candidate["content"] and len(first_candidate["content"]["parts"]) > 0:
                            response_content = first_candidate["content"]["parts"][0]["text"].strip()  # è·å–å“åº”å†…å®¹
                            logger.info(f"Gemini API response content: {response_content}")  # è®°å½•å“åº”å†…å®¹
                            reply_content = response_content.replace("\\n", "\n")  # æ›¿æ¢ \\n ä¸º \n
                        else:
                            logger.error("Parts not found in the Gemini API response content")
                            reply_content = "Parts not found in the Gemini API response content"
                    else:
                        logger.error("Content not found in the Gemini API response candidate")
                        reply_content = "Content not found in the Gemini API response candidate"
                else:
                    logger.error("No candidates available in the Gemini API response")
                    reply_content = "No candidates available in the Gemini API response"        
            else:
                if "choices" in response_data and len(response_data["choices"]) > 0:
                    first_choice = response_data["choices"][0]
                    if "message" in first_choice and "content" in first_choice["message"]:
                        response_content = first_choice["message"]["content"].strip()  # è·å–å“åº”å†…å®¹
                        logger.info(f"OpenAI API response content")  # è®°å½•å“åº”å†…å®¹
                        reply_content = response_content.replace("\\n", "\n")  # æ›¿æ¢ \\n ä¸º \n
                    else:
                        logger.error("Content not found in the response")
                        reply_content = "Content not found in the OpenAI API response"
                else:
                    logger.error("No choices available in the response")
                    reply_content = "No choices available in the OpenAI API response"

        except requests.exceptions.RequestException as e:
            logger.error(f"Error calling OpenAI API: {e}")
            reply_content = f"An error occurred while calling OpenAI API: {e}"

        reply = Reply()
        reply.type = ReplyType.TEXT
        reply.content = f"{remove_markdown(reply_content)}\n\nğŸ’¬5minå†…è¾“å…¥{self.file_sum_qa_prefix}+é—®é¢˜ï¼Œå¯ç»§ç»­è¿½é—®" 
        e_context["reply"] = reply
        e_context.action = EventAction.BREAK_PASS
    def read_pdf(self, file_path):
        logger.info(f"å¼€å§‹è¯»å–PDFæ–‡ä»¶ï¼š{file_path}")
        doc = fitz.open(file_path)
        content = ' '.join([page.get_text() for page in doc])
        logger.info(f"PDFæ–‡ä»¶è¯»å–å®Œæˆï¼š{file_path}")

        return content
    def read_word(self, file_path):
        doc = Document(file_path)
        return ' '.join([p.text for p in doc.paragraphs])
    def read_markdown(self, file_path):
        with open(file_path, 'r', encoding='utf-8') as file:
            md_content = file.read()
            return markdown.markdown(md_content)
    def read_excel(self, file_path):
        workbook = load_workbook(file_path)
        content = ''
        for sheet in workbook:
            for row in sheet.iter_rows():
                content += ' '.join([str(cell.value) for cell in row])
                content += '\n'
        return content
    def read_txt(self, file_path):
        logger.debug(f"å¼€å§‹è¯»å–TXTæ–‡ä»¶: {file_path}")
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                content = file.read()
            logger.debug(f"TXTæ–‡ä»¶è¯»å–å®Œæˆ: {file_path}")
            logger.debug("TXTæ–‡ä»¶å†…å®¹çš„å‰50ä¸ªå­—ç¬¦ï¼š")
            logger.debug(content[:50])  # æ‰“å°æ–‡ä»¶å†…å®¹çš„å‰50ä¸ªå­—ç¬¦
            return content
        except Exception as e:
            logger.error(f"è¯»å–TXTæ–‡ä»¶æ—¶å‡ºé”™: {file_path}ï¼Œé”™è¯¯ä¿¡æ¯: {str(e)}")
            return ""
    def read_csv(self, file_path):
        content = ''
        with open(file_path, 'r', encoding='utf-8') as csvfile:
            reader = csv.reader(csvfile)
            for row in reader:
                content += ' '.join(row) + '\n'
        return content
    def num_tokens_from_string(self, text):
        try:
            encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")
        except KeyError:
            logger.debug(f"Warning: model not found. Using cl100k_base encoding.")
            encoding = tiktoken.get_encoding("cl100k_base")
        return len(encoding.encode(text))
    def read_html(self, file_path):
        with open(file_path, 'r', encoding='utf-8') as file:
            soup = BeautifulSoup(file, 'html.parser')
            return soup.get_text()
    def read_ppt(self, file_path):
        presentation = Presentation(file_path)
        content = ''
        for slide in presentation.slides:
            for shape in slide.shapes:
                if hasattr(shape, "text"):
                    content += shape.text + '\n'
        return content
    def split_text_chinese(self, text, overlap_tokens=500):
        tokens = jieba.cut(text)
        segments = []
        segment_text = ""
        for token in tokens:
            temp_segment_text = segment_text + token
            temp_segment_tokens_count = self.num_tokens_from_string(temp_segment_text)
            if temp_segment_tokens_count >= self.max_tokens:
                segments.append(segment_text)
                previous_segment_text = segment_text
                segment_text = previous_segment_text[-overlap_tokens:] + token if overlap_tokens > 0 else token
            else:
                segment_text = temp_segment_text

        if segment_text:
            segments.append(segment_text)
        logger.debug(f"åˆ†æ®µæ–‡æœ¬: {segments}")
        return segments
    def extract_content(self, file_path):
        logger.info(f"extract_content: æå–æ–‡ä»¶å†…å®¹ï¼Œæ–‡ä»¶è·¯å¾„: {file_path}")

        file_extension = os.path.splitext(file_path)[1][1:].lower()
        logger.info(f"extract_content: æ–‡ä»¶ç±»å‹ä¸º {file_extension}")

        file_type = EXTENSION_TO_TYPE.get(file_extension)

        if not file_type:
            logger.error(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ‰©å±•å: {file_extension}")
            return None

        read_func = {
            'pdf': self.read_pdf,
            'docx': self.read_word,
            'md': self.read_markdown,
            'txt': self.read_txt,
            'excel': self.read_excel,
            'csv': self.read_csv,
            'html': self.read_html,
            'ppt': self.read_ppt
        }.get(file_type)

        if not read_func:
            logger.error(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_type}")
            return None
        logger.info("extract_content: æ–‡ä»¶å†…å®¹æå–å®Œæˆ")
        return read_func(file_path)
    def encode_image_to_base64(self, image_path):
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    # Function to handle OpenAI image processing
    def handle_openai_image(self, base64_image, e_context):
        logger.info("handle_openai_image_response: è§£æOpenAIå›¾åƒå¤„ç†APIçš„å“åº”")
        msg: ChatMessage = e_context["context"]["msg"]
        user_id = msg.from_user_id
        user_params = self.params_cache.get(user_id, {})
        prompt = user_params.get('prompt', self.image_sum_prompt)

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.open_ai_api_key}"
        }

        payload = {
            "model": "gpt-4-vision-preview",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": prompt
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}"
                            }
                        }
                    ]
                }
            ],
            "max_tokens": 3000
        }

        try:
            response = requests.post(f"{self.open_ai_api_base}/chat/completions", headers=headers, json=payload)
            response.raise_for_status()  # å¢åŠ å¯¹HTTPé”™è¯¯çš„æ£€æŸ¥
            response_json = response.json()  # å®šä¹‰response_json
            # ç¡®ä¿å“åº”ä¸­æœ‰ 'choices' é”®å¹¶ä¸”è‡³å°‘æœ‰ä¸€ä¸ªå…ƒç´ 
            if "choices" in response_json and len(response_json["choices"]) > 0:
                first_choice = response_json["choices"][0]
                if "message" in first_choice and "content" in first_choice["message"]:
                    # ä»å“åº”ä¸­æå– 'content'
                    response_content = first_choice["message"]["content"].strip()
                    logger.info("OpenAI API response content")  # è®°å½•å“åº”å†…å®¹
                    reply_content = response_content
                else:
                    logger.error("Content not found in the response")
                    reply_content = "Content not found in the OpenAI API response"
            else:
                logger.error("No choices available in the response")
                reply_content = "No choices available in the OpenAI API response"
        except Exception as e:
            logger.error(f"Error processing OpenAI API response: {e}")
            reply_content = f"An error occurred while processing OpenAI API response: {e}"

        reply = Reply()
        reply.type = ReplyType.TEXT
        reply.content = f"{remove_markdown(reply_content)}\n\nğŸ’¬5minå†…è¾“å…¥{self.image_sum_qa_prefix}+é—®é¢˜ï¼Œå¯ç»§ç»­è¿½é—®"  
        e_context["reply"] = reply
        e_context.action = EventAction.BREAK_PASS
    def handle_gemini_image(self, base64_image, e_context):
        logger.info("handle_gemini_image: è§£æGeminiå›¾åƒå¤„ç†APIçš„å“åº”")
        msg: ChatMessage = e_context["context"]["msg"]
        user_id = msg.from_user_id
        user_params = self.params_cache.get(user_id, {})
        prompt = user_params.get('prompt', self.image_sum_prompt)
        api_key = self.gemini_key
        payload = {
            "contents": [
                {
                    "parts": [
                        {"text": prompt},
                        {
                            "inline_data": {
                                "mime_type":"image/*",
                                "data": base64_image
                            }
                        }
                    ]
                }
            ],
            "generationConfig": {
                "maxOutputTokens": 800
            }
        }

        headers = {
            "Content-Type": "application/json",
            'x-goog-api-key': {api_key}
        }

        try:
            response = requests.post(f"https://generativelanguage.googleapis.com/v1/models/gemini-pro-vision:generateContent", headers=headers, json=payload)
            response.raise_for_status()
            response_json = response.json()
            # æå–å“åº”ä¸­çš„æ–‡æœ¬å†…å®¹
            reply_content = response_json.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text', 'No text found in the response')
        except Exception as e:
            reply_content = f"An error occurred while processing Gemini API response: {e}"

        reply = Reply()
        reply.type = ReplyType.TEXT
        reply.content = f"{remove_markdown(reply_content)}\n\nğŸ’¬5minå†…è¾“å…¥{self.image_sum_qa_prefix}+é—®é¢˜ï¼Œå¯ç»§ç»­è¿½é—®"  
        e_context["reply"] = reply
        e_context.action = EventAction.BREAK_PASS
    def handle_xunfei_image(self, base64_image, e_context):
        global text
        logger.info("handle_xunfei_image_response: è§£æè®¯é£å›¾åƒå¤„ç†APIçš„å“åº”")
        websocket.enableTrace(False)
        wsUrl = self.create_url()
        self.ws_context = e_context
        msg: ChatMessage = e_context["context"]["msg"]
        user_id = msg.from_user_id
        user_params = self.params_cache.get(user_id, {})
        prompt = user_params.get('prompt', self.image_sum_prompt)


        ws = websocket.WebSocketApp(wsUrl, on_message=self.on_message, on_error=self.on_error, on_close=self.on_close, on_open=self.on_open)
        ws.appid = self.xunfei_app_id
        ws.imagedata = base64.b64decode(base64_image)
        text = [{"role": "user", "content": base64_image, "content_type": "image"}]
        ws.question = self.checklen(self.getText("user",prompt))
        ws.run_forever(sslopt={"cert_reqs": ssl.CERT_NONE})



       # ç”Ÿæˆurl
    def create_url(self):
        # ç”ŸæˆRFC1123æ ¼å¼çš„æ—¶é—´æˆ³
        now = datetime.now()
        date = format_date_time(mktime(now.timetuple()))

        # æ‹¼æ¥å­—ç¬¦ä¸²
        signature_origin = "host: " + self.host + "\n"
        signature_origin += "date: " + date + "\n"
        signature_origin += "GET " + self.path + " HTTP/1.1"

        # è¿›è¡Œhmac-sha256è¿›è¡ŒåŠ å¯†
        signature_sha = hmac.new(self.xunfei_api_secret.encode('utf-8'), signature_origin.encode('utf-8'),
                                 digestmod=hashlib.sha256).digest()

        signature_sha_base64 = base64.b64encode(signature_sha).decode(encoding='utf-8')

        authorization_origin = f'api_key="{self.xunfei_api_key}", algorithm="hmac-sha256", headers="host date request-line", signature="{signature_sha_base64}"'

        authorization = base64.b64encode(authorization_origin.encode('utf-8')).decode(encoding='utf-8')

        # å°†è¯·æ±‚çš„é‰´æƒå‚æ•°ç»„åˆä¸ºå­—å…¸
        v = {
            "authorization": authorization,
            "date": date,
            "host": self.host
        }
        # æ‹¼æ¥é‰´æƒå‚æ•°ï¼Œç”Ÿæˆurl
        url = self.ImageUnderstanding_url + '?' + urlencode(v)
        # print(url)
        # æ­¤å¤„æ‰“å°å‡ºå»ºç«‹è¿æ¥æ—¶å€™çš„url,å‚è€ƒæœ¬demoçš„æ—¶å€™å¯å–æ¶ˆä¸Šæ–¹æ‰“å°çš„æ³¨é‡Šï¼Œæ¯”å¯¹ç›¸åŒå‚æ•°æ—¶ç”Ÿæˆçš„urlä¸è‡ªå·±ä»£ç ç”Ÿæˆçš„urlæ˜¯å¦ä¸€è‡´
        return url

    def on_error(self, ws, error):
        e_context = self.ws_context
        reply = Reply()
        reply.type = ReplyType.TEXT
        logger.error(f"Error processing XunFei Image API response: {error}")
        reply_content = f"An error occurred while processing XunFei Image API response: {error}"
        reply.content = remove_markdown(reply_content)  # è®¾ç½®å“åº”å†…å®¹åˆ°å›å¤å¯¹è±¡
        e_context["reply"] = reply
        e_context.action = EventAction.BREAK_PASS


    # æ”¶åˆ°websocketå…³é—­çš„å¤„ç†
    def on_close(self, ws, one, two):
        print(" ")

    # æ”¶åˆ°websocketè¿æ¥å»ºç«‹çš„å¤„ç†
    def on_open(self, ws):
        logger.info(f"[XunFei Image] Start websocket")
        thread.start_new_thread(self.run, (ws,))

    def run(self, ws, *args):
        data = json.dumps(self.gen_params(appid=ws.appid, question=ws.question))
        ws.send(data)

# æ”¶åˆ°websocketæ¶ˆæ¯çš„å¤„ç†
    def on_message(self, ws, message):
        e_context = self.ws_context
        # print(message)
        data = json.loads(message)
        code = data['header']['code']
        message = data['header']['message']
        if code != 0:
            logger.error(f'[XunFei IMage] è¯·æ±‚é”™è¯¯: {code}, {data}')
            reply = Reply()
            reply.type = ReplyType.TEXT
            reply.content = remove_markdown(message)  # è®¾ç½®å“åº”å†…å®¹åˆ°å›å¤å¯¹è±¡
            e_context["reply"] = reply
            e_context.action = EventAction.BREAK_PASS
            ws.close()
        else:
            choices = data["payload"]["choices"]
            status = choices["status"]
            content = choices["text"][0]["content"]
            #logger.info(f"[XunFei IMage]content={content}")
            self.ws_answer += content
            # print(1)
            if status == 2:
                logger.info("XunFei Image API response content")  # è®°å½•å“åº”å†…å®¹
                reply = Reply()
                reply.type = ReplyType.TEXT
                reply.content = reply.content = f"{remove_markdown(self.ws_answer)}\n\nğŸ’¬5minå†…è¾“å…¥{self.image_sum_qa_prefix}+é—®é¢˜ï¼Œå¯ç»§ç»­è¿½é—®"
                e_context["reply"] = reply
                e_context.action = EventAction.BREAK_PASS
                ws.close()
                self.ws_answer = ""

    def gen_params(self, appid, question):
        """
        é€šè¿‡appidå’Œç”¨æˆ·çš„æé—®æ¥ç”Ÿæˆè¯·å‚æ•°
        """

        data = {
            "header": {
                "app_id": appid
            },
            "parameter": {
                "chat": {
                    "domain": "image",
                    "temperature": 0.5,
                    "top_k": 4,
                    "max_tokens": 2028,
                    "auditing": "default"
                }
            },
            "payload": {
                "message": {
                    "text": question
                }
            }
        }

        return data
    def getText(self, role, content):
        jsoncon = {}
        jsoncon["role"] = role
        jsoncon["content"] = content
        text.append(jsoncon)
        return text
    def getlength(self, text):
        length = 0
        for content in text:
            temp = content["content"]
            leng = len(temp)
            length += leng
        return length
    def checklen(self, text):
        #print("text-content-tokens:", getlength(text[1:]))
        while (self.getlength(text[1:])> 8000):
            del text[1]
        return text

def remove_markdown(text):
    # æ›¿æ¢Markdownçš„ç²—ä½“æ ‡è®°
    text = text.replace("**", "")
    # æ›¿æ¢Markdownçš„æ ‡é¢˜æ ‡è®°
    text = text.replace("### ", "").replace("## ", "").replace("# ", "")
    return text